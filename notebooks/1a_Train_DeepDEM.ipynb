{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to use train a convolutional neural network for DEM refinement. We leverage `pytorch`, `pytorch-lightning`, `torchgeo` as part of our ML stack. Our model follows the `UNet` architecture and incorporates a few variations in the form of `ResNet` backbones and additional skip connections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch imports\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from lightning.pytorch.callbacks import LearningRateMonitor, ModelCheckpoint\n",
    "import lightning as L\n",
    "import torch\n",
    "from torch import nn \n",
    "\n",
    "# torchgeo imports\n",
    "from torchgeo.datasets import stack_samples\n",
    "\n",
    "# misc imports\n",
    "from pathlib import Path\n",
    "import kornia.augmentation as K\n",
    "import sys\n",
    "\n",
    "# local imports\n",
    "sys.path.insert(0, str(Path('.').absolute().parent/'lib'))\n",
    "sys.path.insert(0, str(Path('.').absolute().parent))\n",
    "from lib.dataset_modules import CustomDataModule\n",
    "from lib.task_module import DeepDEMRegressionTask\n",
    "\n",
    "torch.set_float32_matmul_precision('medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic hyperparameters\n",
    "BATCH_SIZE = 24\n",
    "NUM_WORKERS = 12\n",
    "CHANNEL_SWAP = True # Swap the two stereo channels to generalize training\n",
    "FAST_DEV_RUN = False # Set to True if doing debugging/sanity check run\n",
    "CHIP_SIZE = 256 # Size of model input chips\n",
    "MODEL_ENCODER = 'resnet18'\n",
    "\n",
    "# this can be 'unet' for ResDepth architecture or 'smp-unet' for UNet with ResNet encoder\n",
    "MODEL_TYPE = 'smp-unet' \n",
    "\n",
    "# Determines the fraction of the image used for training along x-axis, manually determined\n",
    "# For the Mt Baker dataset, there are large swathes of no-data region on one side of the image\n",
    "# necessitating a peculiar split instead of the typical 90/10\n",
    "TRAIN_SPLIT = 0.65 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image augmentation transforms\n",
    "# These would be applied to the images during training\n",
    "transforms = nn.Sequential(\n",
    "    K.RandomHorizontalFlip(p=0.5),\n",
    "    K.RandomVerticalFlip(p=0.5),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bands that will be use as model inputs\n",
    "bands = [\n",
    "    \"asp_dsm\",\n",
    "    \"ortho_left\",\n",
    "    \"ortho_right\",\n",
    "    \"ndvi\",\n",
    "    \"nodata_mask\",\n",
    "    \"triangulation_error\",\n",
    "    \"lidar_data\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to processed rasters generated from 0c_Data_Preprocessing.ipynb \n",
    "datapath = '/mnt/working/karthikv/DeepDEM/data/mt_baker/WV01_20150911_1020010042D39D00_1020010043455300/processed_rasters'\n",
    "\n",
    "# Datamodule parameters\n",
    "datamodule_params = {\n",
    "    'dataset_class':CustomDataModule,\n",
    "    'chip_size': CHIP_SIZE,\n",
    "    'batch_size':BATCH_SIZE,\n",
    "    'num_workers':NUM_WORKERS,\n",
    "    'collate_fn':stack_samples,\n",
    "    'cuda': torch.cuda.is_available(),\n",
    "    'train_aug':transforms,\n",
    "    'train_split':TRAIN_SPLIT,\n",
    "    'paths':datapath,\n",
    "    'bands':bands\n",
    "}\n",
    "\n",
    "# Model kwargs\n",
    "model_kwargs = {\n",
    "    'chip_size': CHIP_SIZE,\n",
    "    'encoder_weights':'imagenet',\n",
    "    'channel_swap':CHANNEL_SWAP,\n",
    "    'do_BN':False,\n",
    "    'bias_conv_layer':False,\n",
    "    'lr':5e-4,\n",
    "    'num_workers':NUM_WORKERS,\n",
    "    'max_epochs':300,\n",
    "    'lr_scheduler':True,\n",
    "    'lr_scheduler_scale_factor':0.5,\n",
    "    'lr_scheduler_patience':50,\n",
    "    'early_stopping':True,\n",
    "    'earlystopping_patience':75,\n",
    "    'datapath':datapath,\n",
    "    'train_split':TRAIN_SPLIT,\n",
    "    'bands':bands,\n",
    "    'encoder':MODEL_ENCODER,\n",
    "    'model':MODEL_TYPE,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule = CustomDataModule(**datamodule_params)\n",
    "task = DeepDEMRegressionTask(**model_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_directory = Path(f'./checkpoints/deep_dem_experiment')\n",
    "checkpoint_directory.mkdir(exist_ok=True, parents=True)\n",
    "model_count = len([x for x in list(checkpoint_directory.glob('*')) if x.is_dir()]) + 1\n",
    "\n",
    "checkpoint_directory = checkpoint_directory / f\"version_{str(model_count).zfill(3)}\"\n",
    "checkpoint_directory.mkdir(exist_ok=False)\n",
    "\n",
    "# Callbacks get passed to the trainer\n",
    "callbacks = [\n",
    "    LearningRateMonitor(logging_interval='step'), \n",
    "    ModelCheckpoint(dirpath=checkpoint_directory, monitor='val_loss', mode='min')\n",
    "]\n",
    "\n",
    "# if early stopping is set in model kwargs, stop training after conditions are met\n",
    "if model_kwargs['early_stopping']:\n",
    "    callbacks.append(EarlyStopping(monitor=\"val_loss\", \n",
    "    min_delta=0.05, \n",
    "    patience=model_kwargs['earlystopping_patience'], \n",
    "    verbose=True, mode=\"min\")) # type: ignore\n",
    "\n",
    "# setup logger for tensorboard\n",
    "logger = TensorBoardLogger(save_dir=\"logs/\", name=f\"deep_dem_experiment\")\n",
    "\n",
    "# define trainer\n",
    "trainer = L.Trainer(accelerator = \"gpu\" if torch.cuda.is_available() else \"cpu\", \n",
    "                    default_root_dir=checkpoint_directory, \n",
    "                    max_epochs=model_kwargs['max_epochs'], logger=logger, check_val_every_n_epoch=1, # type: ignore\n",
    "                    log_every_n_steps=1, fast_dev_run=FAST_DEV_RUN, # set fast_dev_run to True for sanity check (dummy run) before training \n",
    "                    callbacks=callbacks) # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run training\n",
    "trainer.fit(model=task, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model weights\n",
    "torch.save(task.model.state_dict(), checkpoint_directory/f\"deepdem_model_weights.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training progress can be monitored by running tensorboard using the following commands:\n",
    "\n",
    "`\n",
    "tensorboard --logdir='./tensorboard_dirs' --port=<specify port number of choice>\n",
    "`\n",
    "\n",
    "and then navigating to the following URL in a browser:\n",
    "\n",
    "`\n",
    "http://localhost:<port number>/\n",
    "`\n",
    "\n",
    "If the training is happening on a remote machine, we can open an ssh connection to the remote machine:\n",
    "\n",
    "`\n",
    "ssh -N -f -L <local port>:127.0.0.1:<remote machine port> <username>@<server>\n",
    "`\n",
    "\n",
    "Followed by accessing `http://localhost:<local port>/`\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_dem",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
