{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to generate inference for a scene using a previously trained DeepDEM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rasterio imports\n",
    "import rasterio\n",
    "from rasterio.merge import merge\n",
    "\n",
    "from rasterio import transform\n",
    "\n",
    "# torchgeo imports\n",
    "from torchgeo.samplers import GridGeoSampler\n",
    "# from torchgeo.datasets import RasterDataset\n",
    "\n",
    "# pytorch imports \n",
    "import torch\n",
    "\n",
    "# misc imports\n",
    "from functools import reduce, partial\n",
    "# import operator\n",
    "from pathlib import Path, PurePath\n",
    "import numpy as np\n",
    "\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "\n",
    "import kornia.augmentation as K\n",
    "\n",
    "\n",
    "# local imports\n",
    "import sys\n",
    "sys.path.insert(0, str(Path('.').absolute().parent/'scripts'))\n",
    "\n",
    "from task_module import DeepDEMRegressionTask\n",
    "from dataset_modules import CustomInputDataset, CustomDataModule\n",
    "from torchgeo.datasets import stack_samples\n",
    "from torchgeo.samplers import BatchGeoSampler\n",
    "from torch import nn \n",
    "from functools import partial\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path= Path('/mnt/working/karthikv/DeepDEM/scripts/checkpoints/experiment_group_1/version_001/')\n",
    "model_checkpoint = list(model_path.glob('*.ckpt'))[0]\n",
    "model = DeepDEMRegressionTask.load_from_checkpoint(model_checkpoint).cuda().eval();\n",
    "# model.model_kwargs['channel_swap'] = False\n",
    "\n",
    "bands, datapath, chip_size = model.model_kwargs['bands'], model.model_kwargs['datapath'], model.model_kwargs['chip_size']\n",
    "bands.remove('lidar_data')\n",
    "inference_dataset = CustomInputDataset(datapath, bands=bands)\n",
    "data_sampler = GridGeoSampler(inference_dataset, size=chip_size, stride=chip_size//2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with rasterio.open(inference_dataset.files[0]) as ds:\n",
    "    template_profile = ds.profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_write_inference(index, sample, dataset, model, output_path, template_profile):\n",
    "    \n",
    "    if not isinstance(output_path, PurePath):\n",
    "        output_path = Path(output_path)\n",
    "    if not output_path.exists():\n",
    "        output_path.mkdir()\n",
    "\n",
    "    item = dataset.__getitem__(sample)\n",
    "    inference = model.forward(item['image'].reshape(1, *item['image'].shape).cuda(), stage='inference').cpu().detach().numpy().squeeze()\n",
    "    \n",
    "    bounds = (sample.minx, sample.miny, sample.maxx, sample.maxy)\n",
    "\n",
    "    dst_transform = transform.from_bounds(*bounds, *inference.shape[::-1])\n",
    "\n",
    "    template_profile.update({\n",
    "        'width':inference.shape[-1],\n",
    "        'height':inference.shape[-2],\n",
    "        'transform':dst_transform\n",
    "    })\n",
    "\n",
    "    with rasterio.open(output_path / f\"inference_{str(index).zfill(6)}.tif\", 'w', **template_profile) as ds:\n",
    "        ds.write(inference.reshape(1, *inference.shape))\n",
    "\n",
    "\n",
    "model_name = '_'.join(str(model_path).split('/')[-2:])\n",
    "output_path = Path(f'../outputs/{model_name}')\n",
    "\n",
    "generate_write_inference = partial(generate_write_inference, output_path=output_path, \n",
    "                                   dataset=inference_dataset, \n",
    "                                   model=model,\n",
    "                                   template_profile=template_profile)\n",
    "\n",
    "for i, sample in enumerate(data_sampler):\n",
    "    generate_write_inference(i, sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inferences = sorted(list(output_path.glob('inference_*.tif')))[::-1]\n",
    "merged_inference, merge_transform = merge(inferences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_profile = template_profile.copy()\n",
    "inference_profile['height'] = merged_inference.shape[-2]\n",
    "inference_profile['width'] = merged_inference.shape[-1]\n",
    "inference_profile['transform'] = merge_transform\n",
    "\n",
    "with rasterio.open(output_path.parent / f'{output_path.name}.tif', 'w', **inference_profile) as ds:\n",
    "    ds.write(merged_inference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subprocess.run([\"gdaldem\", \"hillshade\", \"-compute_edges\", output_path.parent / f'{output_path.name}.tif', output_path.parent / f'{output_path.name}_hs.tif'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_dem",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
