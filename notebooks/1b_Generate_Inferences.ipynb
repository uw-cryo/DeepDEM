{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to generate inference for a scene using a previously trained DeepDEM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rasterio imports\n",
    "import rasterio\n",
    "from rasterio.merge import merge\n",
    "from rasterio import transform\n",
    "\n",
    "# torchgeo imports\n",
    "from torchgeo.samplers import GridGeoSampler\n",
    "\n",
    "# pytorch imports \n",
    "import torch\n",
    "\n",
    "# misc imports\n",
    "from functools import partial\n",
    "from pathlib import Path, PurePath\n",
    "import subprocess\n",
    "\n",
    "# local imports\n",
    "import sys\n",
    "sys.path.insert(0, str(Path('.').absolute().parent/'scripts'))\n",
    "\n",
    "from task_module import DeepDEMRegressionTask\n",
    "from dataset_modules import CustomInputDataset, CustomDataModule\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path= Path('/mnt/working/karthikv/DeepDEM/scripts/checkpoints/experiment_group_1/version_001/')\n",
    "model_checkpoint = list(model_path.glob('*.ckpt'))[0]\n",
    "model = DeepDEMRegressionTask.load_from_checkpoint(model_checkpoint).cuda().eval();\n",
    "# model.model_kwargs['channel_swap'] = False\n",
    "\n",
    "bands, datapath, chip_size = model.model_kwargs['bands'], model.model_kwargs['datapath'], model.model_kwargs['chip_size']\n",
    "bands.remove('lidar_data')\n",
    "inference_dataset = CustomInputDataset(datapath, bands=bands)\n",
    "data_sampler = GridGeoSampler(inference_dataset, size=chip_size, stride=chip_size//2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with rasterio.open(inference_dataset.files[0]) as ds:\n",
    "    template_profile = ds.profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_write_inference(index, samples, chip_size, dataset, model, output_path, template_profile):\n",
    "    \n",
    "    if not isinstance(output_path, PurePath):\n",
    "        output_path = Path(output_path)\n",
    "    if not output_path.exists():\n",
    "        output_path.mkdir()\n",
    "\n",
    "    img = []\n",
    "    bounds = []    \n",
    "    template_profile.update({\n",
    "        'width':chip_size,\n",
    "        'height':chip_size\n",
    "        })\n",
    "\n",
    "    # manually create a batch of images\n",
    "    for sample in samples:\n",
    "        item = dataset.__getitem__(sample)\n",
    "        img.append(item['image'])\n",
    "        bounds.append((sample.minx, sample.miny, sample.maxx, sample.maxy))\n",
    "    \n",
    "    # perform inference on a batch of images\n",
    "    inference = model.forward(torch.stack(img, dim=0).cuda(), stage='inference').cpu().detach().numpy()\n",
    "    \n",
    "    # calculate transform for each tile and write it out\n",
    "    for i in range(inference.shape[0]):\n",
    "        template_profile.update({\n",
    "            'transform':transform.from_bounds(*bounds[i], chip_size, chip_size)\n",
    "        })\n",
    "\n",
    "        with rasterio.open(output_path / f\"inference_{str(index+i).zfill(7)}.tif\", 'w', **template_profile) as ds:\n",
    "            ds.write(inference[i].reshape(1, *inference[i].shape))\n",
    "\n",
    "\n",
    "model_name = '_'.join(str(model_path).split('/')[-2:])\n",
    "output_path = Path(f'../outputs/{model_name}')\n",
    "\n",
    "generate_write_inference = partial(generate_write_inference, \n",
    "                                   chip_size=chip_size,\n",
    "                                   model=model,\n",
    "                                   dataset=inference_dataset,\n",
    "                                   output_path=output_path,\n",
    "                                   template_profile=template_profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiprocessing doesn't work well within jupyter notebooks\n",
    "# \n",
    "BATCH_SIZE = 1\n",
    "data_sampler = list(data_sampler)\n",
    "for i in range(len(data_sampler)):\n",
    "    generate_write_inference(index=i, samples=data_sampler[i:i+BATCH_SIZE])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inferences = sorted(list(output_path.glob('inference_*.tif')))[::-1]\n",
    "merged_inference, merge_transform = merge(inferences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_profile = template_profile.copy()\n",
    "inference_profile['height'] = merged_inference.shape[-2]\n",
    "inference_profile['width'] = merged_inference.shape[-1]\n",
    "inference_profile['transform'] = merge_transform\n",
    "\n",
    "with rasterio.open(output_path.parent / f'{output_path.name}.tif', 'w', **inference_profile) as ds:\n",
    "    ds.write(merged_inference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subprocess.run([\"gdaldem\", \"hillshade\", \"-compute_edges\", output_path.parent / f'{output_path.name}.tif', output_path.parent / f'{output_path.name}_hs.tif'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_dem",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
