{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook steps through data preprocessing steps needed prior to DSM refinement. In particular:\n",
    "\n",
    "- Crop all raster extents to the same bounds\n",
    "- Reproject and resample all rasters to the same CRS and resolution\n",
    "- Create a no-data mask file\n",
    "- Calculate NDVI from HLS data and write out a new raster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GIS imports\n",
    "import rasterio\n",
    "from rasterio.windows import from_bounds\n",
    "from rasterio.warp import Resampling, reproject, transform_bounds\n",
    "from shapely.geometry import box\n",
    "\n",
    "# misc imports\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our input dataset comprises of two ortho images, the initial DSM generated from these images (in our case, using [ASP](https://stereopipeline.readthedocs.io/en/latest/introduction.html)), co-incident NDVI values (derived from [HLS data](https://hls.gsfc.nasa.gov/)), and finally triangulation errors and nodata values obtained from the ASP processing of the ortho images.\n",
    "\n",
    "Users will need to specify the path to the rasters as well as the specific filenames below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user specified filepaths and filenames\n",
    "input_data_path = Path('/mnt/1.0_TB_VOLUME/karthikv/DeepDEM/data/baker_csm_stack/original_rasters/') # specify folder path containing source rasters\n",
    "output_data_path = input_data_path.parent / 'processed_rasters' # preprocessed data will be written to this location\n",
    "output_data_path.mkdir(exist_ok=True)\n",
    "\n",
    "# specify filenames for the ortho images, initial DSM, HLS data, triangulation errors, and the ground truth LIDAR data\n",
    "ortho_left_file = 'final_ortho_left_1.0m_holes_filled.tif'\n",
    "ortho_right_file = 'final_ortho_right_1.0m_holes_filled.tif'\n",
    "initial_dsm_file = 'try_pc_align_to_lidar_15m_maxdisp_rotationallowed-1.0m-DEM_holes_filled.tif'\n",
    "hls_red_band_file = 'HLS.L30.T10UEV.2015254T185445.v2.0.B04.tif'\n",
    "hls_nir_band_file = 'HLS.L30.T10UEV.2015254T185445.v2.0.B05.tif'\n",
    "triangulation_error_file = 'try_pc_align_to_lidar_15m_maxdisp_rotationallowed-1.0m-IntersectionErr.tif'\n",
    "lidar_data_file = 'mosaic_full128_USGS_LPC_WA_MtBaker_2015_*_LAS_2017_32610_first_filt_v1.3_1.0m-DEM_holes_filled.tif' \n",
    "\n",
    "\n",
    "# We define a dictionary using the user defined values provided above\n",
    "input_file_dict = {\n",
    "    'ortho_left':ortho_left_file,\n",
    "    'ortho_right':ortho_right_file,\n",
    "    'asp_dsm':initial_dsm_file,\n",
    "    'hls_red':hls_red_band_file,\n",
    "    'hls_nir':hls_nir_band_file,\n",
    "    'triangulation_error':triangulation_error_file,\n",
    "    'lidar_data':lidar_data_file\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_folder_path = input_data_path / 'tmp'\n",
    "tmp_folder_path.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open files, create shapely polygons from bounds, intersect them and find common overlap\n",
    "# Then perform a windowed read of the files, and write out the cropped rasters\n",
    "\n",
    "with rasterio.open(input_data_path / ortho_left_file) as ds:\n",
    "    reference_crs = ds.crs\n",
    "    reference_x_resolution = abs(ds.transform[0])\n",
    "    reference_y_resolution = abs(ds.transform[4])\n",
    "\n",
    "shapes = []\n",
    "for key, value in input_file_dict.items():\n",
    "    with rasterio.open(input_data_path / value) as ds:\n",
    "        src_crs = ds.crs\n",
    "        shapes.append(box(*transform_bounds(src_crs, reference_crs, *ds.bounds)))\n",
    "\n",
    "intersection_shape =  shapes[0]\n",
    "for s in shapes:\n",
    "    intersection_shape = intersection_shape.intersection(s)\n",
    "\n",
    "print(f\"Bounds of intersection area across rasters in {reference_crs}: \", intersection_shape.bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We now perform windowed reads of the rasters and write out new files\n",
    "\n",
    "def write_output_rasters(key_val):\n",
    "\n",
    "    window_read_bounds = intersection_shape.bounds\n",
    "\n",
    "    key, value = key_val\n",
    "    output_file = output_data_path / f\"final_{key}.tif\"\n",
    "\n",
    "    with rasterio.open(input_data_path / value) as ds:\n",
    "        tmp_profile = ds.profile\n",
    "\n",
    "        if ds.crs != reference_crs:\n",
    "            # if the input data CRS does not match the reference CRS, we perform a windowed read of the \n",
    "            # relevant area, and then reproject + resample the data to the reference CRS.\n",
    "\n",
    "            tmp_window_bounds = transform_bounds(reference_crs, ds.crs, *window_read_bounds)\n",
    "            img = ds.read(1, window=from_bounds(*tmp_window_bounds, transform=ds.transform))\n",
    "            \n",
    "            # this is the transform associated with the windowed read in the reference crs\n",
    "            src_transform = rasterio.transform.from_bounds(*tmp_window_bounds, img.shape[-1], img.shape[-2])\n",
    "            \n",
    "            # this is the transform associated with the windowed read in the reference crs\n",
    "            width = int((window_read_bounds[2] - window_read_bounds[0])/reference_x_resolution)\n",
    "            height = int((window_read_bounds[3] - window_read_bounds[1])/reference_y_resolution)\n",
    "\n",
    "            dst_transform = rasterio.transform.from_bounds(*window_read_bounds, width, height)\n",
    "\n",
    "            # create the reprojected+resampled raster\n",
    "            dst_raster = np.zeros((height, width))\n",
    "            \n",
    "            reproject(\n",
    "                source=img, \n",
    "                destination=dst_raster, \n",
    "                src_transform=src_transform, \n",
    "                src_crs=ds.crs, \n",
    "                dst_transform=dst_transform, \n",
    "                dst_crs=reference_crs,\n",
    "                resampling=Resampling.nearest\n",
    "            )\n",
    "\n",
    "            # we will write out this img temporarily to perform a windowed read\n",
    "            tmp_profile_copy = tmp_profile.copy()\n",
    "            tmp_profile_copy.update({\n",
    "                'transform':dst_transform,\n",
    "                'width':width,\n",
    "                'height':height,\n",
    "                'crs':reference_crs\n",
    "            })\n",
    "\n",
    "            with rasterio.open(tmp_folder_path/'tmp.tif', 'w', **tmp_profile_copy) as output:\n",
    "                output.write(dst_raster.reshape(1, *dst_raster.shape))\n",
    "\n",
    "            # perform windowed read\n",
    "            with rasterio.open(tmp_folder_path/'tmp.tif') as input:\n",
    "                dst_raster = input.read(1, window=from_bounds(*window_read_bounds, transform=input.transform))\n",
    "\n",
    "            # delete temporary files\n",
    "            (tmp_folder_path/'tmp.tif').unlink()\n",
    "\n",
    "        else:\n",
    "            dst_raster = ds.read(1, window=from_bounds(*window_read_bounds, transform=ds.transform))\n",
    "\n",
    "    transform = rasterio.transform.from_bounds(*window_read_bounds, width=dst_raster.shape[-1], height=dst_raster.shape[-2])\n",
    "\n",
    "    tmp_profile.update({\n",
    "        'width':dst_raster.shape[-1],\n",
    "        'height':dst_raster.shape[-2],\n",
    "        'transform':transform,\n",
    "        'crs':reference_crs,\n",
    "        'blockxsize':256, \n",
    "        'blockysize':256,\n",
    "        'compress': 'deflate',\n",
    "        'tiled': True,\n",
    "        })\n",
    "    \n",
    "    if key == 'triangulation_error':\n",
    "        dst_raster = np.where(dst_raster==tmp_profile['nodata'], 1, dst_raster)\n",
    "        tmp_profile.update({\n",
    "            'nodata':1\n",
    "        })\n",
    "    \n",
    "    with rasterio.open(output_file, 'w', **tmp_profile) as ds:\n",
    "        ds.write(dst_raster.reshape(1, *dst_raster.shape))\n",
    "    \n",
    "    print(f\"Written out: {output_file.name}\")\n",
    "\n",
    "_ = list(map(write_output_rasters, tqdm(list(input_file_dict.items()))))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's calculate NDVI values from the HLS data and write them out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nir_file = output_data_path / 'final_hls_nir.tif'\n",
    "red_file = output_data_path / 'final_hls_red.tif'\n",
    "\n",
    "assert nir_file.exists(), \"Error, processed HLS NIR band file missing\"\n",
    "assert red_file.exists(), \"Error, processed HLS red band file missing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with rasterio.open(nir_file) as ds:\n",
    "    profile = ds.profile\n",
    "    nodata_value = ds.profile['nodata']\n",
    "    nir_img = ds.read(1)\n",
    "    nir_img = np.ma.masked_where(nir_img == nodata_value, nir_img)\n",
    "\n",
    "with rasterio.open(red_file) as ds:\n",
    "    nodata_value = ds.profile['nodata']\n",
    "    red_img = ds.read(1)\n",
    "    red_img = np.ma.masked_where(red_img == nodata_value, red_img)\n",
    "\n",
    "ndvi = (nir_img - red_img)/(nir_img + red_img)\n",
    "\n",
    "# set bad values to zero.\n",
    "ndvi = np.where(((ndvi<-1) | (ndvi>1)), 0, ndvi)\n",
    "\n",
    "# ndvi can take float values\n",
    "profile.update({'dtype':ndvi.dtype})\n",
    "\n",
    "with rasterio.open(output_data_path/\"final_ndvi.tif\", 'w', **profile) as ds:\n",
    "    ds.write(ndvi.reshape(1, *ndvi.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, let's write out a no-data mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodata_mask = np.zeros_like(ndvi)\n",
    "\n",
    "for i, file in enumerate(output_data_path.glob('*.tif')):\n",
    "    \n",
    "    # ignore contents of a mask file if it already exists\n",
    "    if file.name == 'final_nodata_mask.tif':\n",
    "        continue\n",
    "\n",
    "    with rasterio.open(file) as src:\n",
    "        if i == 0:\n",
    "            profile = src.profile # for later use\n",
    "\n",
    "        # any region marked as 'no-data' will have a non-zero value in the mask\n",
    "        # valid data regions will be 0\n",
    "        nodata_mask += np.where(src.read(1) == src.profile['nodata'], 1, 0)\n",
    "    \n",
    "# invert values so that nodata regions are marked as 0, valid data regions are marked 1\n",
    "nodata_mask = np.where(nodata_mask != 0, 0, 1)\n",
    "profile.update({'dtype':nodata_mask.dtype, 'nodata':None})\n",
    "\n",
    "with rasterio.open(output_data_path/'final_nodata_mask.tif', 'w', **profile) as dst:\n",
    "    dst.write(nodata_mask.reshape(1, *nodata_mask.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We expect 9 files at the end of processing (2 ortho images, 1 DSM, 2 HLS images, 1 NDVI, triangulation error, nodata mask, LIDAR DEM)\n",
    "assert len(list(output_data_path.glob('*.tif')))==9, 'One or more files were not processed!'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_dem",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
