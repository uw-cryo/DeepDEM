{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d23e992b-66c2-47c6-bfd9-8cfac8dd2152",
   "metadata": {},
   "source": [
    "# DeepDEM demo\n",
    "- Seth Vanderwilt\n",
    "- 11/1/23"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a28899-e8d8-49dc-a9e7-8d06e3c4f546",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6de925d-b45a-46df-b377-71c6ae5b9460",
   "metadata": {},
   "source": [
    "**Today's demo**\n",
    "- Overview of the workflow:\n",
    "    - Process stereo imagery into DEM + orthoimages + intersection error which are self-consistent and aligned with the lidar target DEM.\n",
    "    - Using torchgeo and lightning, load these raster stacks (onto GPU, if availalble) and train neural networks to refine the initial stereo DEM using lidar DEM as supervision, with the goal of restoring terrain features, eliminating artifacts, etc.\n",
    "    - Run inference on training datasets or other raster stacks to evaluate refinement quality\n",
    "- Show training & inference with either 3km x 3km Easton Glacier demo area subset, or larger 128km^2 Mount Baker stack\n",
    "- With identical layer & normalization settings (the 5 input layers, `meanstd` normalization) reuse existing checkpoints such as `version_145/checkpoints/epoch=12366-step=3091750.ckpt` as starting point for training or use directly for inference\n",
    "- Tips for processing, experiments, and evaluation\n",
    "- Code suggestions to increase flexibility for future experiments:\n",
    "    - Continue modularization and use of LightningCLI / torchgeo tools to ingest and preprocess datasets in a more flexible way than currently implemented.\n",
    "    - Fix a naming scheme for input layers to avoid having to specify each individual dataset in configuration files and `torchgeo_dataset.py`\n",
    "\n",
    "**Notes:**\n",
    "- The latest [torchgeo](https://github.com/microsoft/torchgeo/) v0.5.0 may cause issues with its GridGeoSampler output for rasters that are not a multiple of the patch size (i.e. grid sampler failing along the edges where available pixels don't match patch size) - unknown changes since v0.4.1 for loading files and producing an output raster\n",
    "- Also unknown LightningCLI changes may affect the functionality of this code\n",
    "\n",
    "**Next steps for any users:**\n",
    "- Configure environment appropriately\n",
    "- Create/download desired dataset stack to use, input normalization strategy, etc. and revise the dataset implementation and filepaths as needed\n",
    "    - Suggestion: 1 training stack + 1 validation stack, OR split a single stack of GeoTIFFs into pre-defined tiles (e.g. using USGS 3DEP tile boundaries, 116km^2 of training tiles interspersed with 12km^2 of validation tiles)\n",
    "- Choose a model checkpoint from Google Drive experiment checkpoints (for the case of 5 input layers `DSM-Ortho1-Ortho2-TriError-NodataMask` and `meanstd` normalization), or start from scratch.\n",
    "- Revise configuration YAML file to match desired training hyperparameters, model, ...\n",
    "- Look through torchgeo and lightning docs, especially with LightningCLI integration updates described in [0.5.0](https://github.com/microsoft/torchgeo/releases/tag/v0.5.0)\n",
    "    - this points to a potentially better way to define and load the dataset compared to current `torchgeo_dataset.py` implementation\n",
    "    - LightningCLI fit / predict / validate / test setup may be useful to avoid current redundant code in training and inference scripts (basically, separate configuration from code more)\n",
    "- Pick a descriptive file naming scheme for experiments and checkpoints (not just version numbers) and include metadata (descriptions) to track each run\n",
    "\n",
    "**Steps for larger changes:**\n",
    "- Look into refactoring the LightningModule `resdepth_lightning_module.py` and LightningDataModule `tgdsm_lightning_data_module.py` implementations and their supporting files to allow specification input layers, parameters, normalization, passing in different models/losses in configuration files. Main thing to handle is getting all layers in expected order with correct transformations, which were hardcoded per-layer for initial experiments\n",
    "- Follow [Lightning documentation](https://lightning.ai/docs/pytorch/stable/api/lightning.pytorch.cli.LightningCLI.html) for modifying configuration files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b161acba-606a-4870-9b28-d0101b887df2",
   "metadata": {},
   "source": [
    "## Setting up the code (& get the repo from GitHub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce9466a-0bff-4ddd-8f86-5bf5234ceb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dir = \"/Users/seth/Desktop/deepDEM_test\"\n",
    "script_dir = os.path.join(main_dir, \"DeepDEM/ResDepth/torchgeo_experiments\")\n",
    "\n",
    "%cd $main_dir\n",
    "# git clone DeepDEM # into this directory\n",
    "repo_dir = os.path.join(main_dir, \"DeepDEM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df548a81-90db-4a8f-a6e5-e8fb2886946c",
   "metadata": {},
   "source": [
    "### Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a7a5b9-72d4-4059-9cf8-a62ab625ce57",
   "metadata": {},
   "source": [
    "* Note: using another conda environment without the CUDA requirements, and with torchgeo pinned to 0.4.1 - some torchgeo changes over the last months seem to break the inference.py script when copying output patches to the resulting raster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3aa715c-2cf6-428d-9a3d-f9d53538ed2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mamba env create --file DeepDEM/environment_torchgeo041_no_gpu.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba37a142-478b-4b8d-89e1-b7721bf9b552",
   "metadata": {},
   "source": [
    "### Files to modify:\n",
    "* `DeepDEM/ResDepth/torchgeo_experiments/torchgeo_dataset.py`\n",
    "    * change the `files` attribute of the class to some other name\n",
    "* `DeepDEM/ResDepth/torchgeo_experiments/inference.py`\n",
    "    * revise path to Stucker & Schindler ResDepth repo\n",
    "    * reduce tile (patch) size\n",
    "    * specify validation directory and dataset type for `torchgeo_dataset.py` loading\n",
    "* `DeepDEM/ResDepth/torchgeo_experiments/resdepth_lightning_module.py`\n",
    "    * revise path to Stucker & Schindler ResDepth repo\n",
    "* `DeepDEM/configs/` suggested way: copy the example, create a new configuration YAML file and set the necessary values\n",
    "    * To create a new YAML from scratch, use `python train_cli.py fit --print_config\n",
    "` based on [Lightning docs](https://lightning.ai/docs/pytorch/stable/cli/lightning_cli_advanced.html#prepare-a-config-file-for-the-cli)\n",
    "    * `max_epochs` perhaps set to 1234567890 in order to resume from previous checkpoints with > 1000 epochs\n",
    "    * `ckpt_path` to resume from a `.ckpt` checkpoint\n",
    "    * `normalization` to `meanstd`\n",
    "    * `batch_size` reduce to e.g. 2 depending on hardware, model\n",
    "    * `train_directory` and `val_directory` paths to desired datasets\n",
    "* `DeepDEM/environment.yml`\n",
    "    * remove CUDA if needed\n",
    "    * pin version(s): only `torchgeo` 0.4.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54980ee3-012a-43e0-b420-a2b427abb43a",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351d6d78-8d25-4902-bcc5-495242178d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import rioxarray as rxr\n",
    "from osgeo import gdal\n",
    "\n",
    "from matplotlib_scalebar.scalebar import ScaleBar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1216c28-8bdd-472f-a32e-97c20cfa2b86",
   "metadata": {},
   "source": [
    "## Make a smaller subset of the Mount Baker dataset (~3 km x 3 km)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fef27e-a8f9-4fd8-ac79-f8890f12398f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Due to potential changes in latest torchgeo for edge of raster behavior, use even multiples of the patch size for this test dataset\n",
    "# Easton glacier demo area\n",
    "xmin = 584000\n",
    "xmax = 587072\n",
    "ymin = 5397000\n",
    "ymax = 5400072"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef057038-17cb-48b0-96be-62d069ef2703",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for full_size_fn in glob.glob(\"baker_csm_stack/*.tif\"):\n",
    "    small_fn = os.path.join(\"baker_csm_stack_small\", os.path.basename(full_size_fn))\n",
    "    print(f\"Crop {full_size_fn} to {small_fn}\")\n",
    "    !gdalwarp -overwrite -r cubic -te $xmin $ymin $xmax $ymax \"$full_size_fn\" \"$small_fn\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b983e676-1c79-498e-a22d-b75c020067ca",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Helper functions copied from `presentation_figures.ipynb` in repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d510e103-e550-46ed-81a1-da4289db49cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ortho(ax,ortho,title, scale=1, fixed_value=50, show_scalebar=True):\n",
    "    im = ax.imshow(ortho, cmap=\"gray\", rasterized=True) # just want true range for colorbar\n",
    "    ortho = stretch_image(ortho)\n",
    "    im = ax.imshow(ortho, cmap=\"gray\", rasterized=True)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_aspect(1)\n",
    "    ax.set_title(title)\n",
    "\n",
    "    # Include scalebar\n",
    "    # scale in meters\n",
    "    if show_scalebar:\n",
    "        ax.add_artist(ScaleBar(scale, fixed_value=fixed_value))\n",
    "    plt.colorbar(im, ax=ax, fraction=0.04)\n",
    "\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e8f503-3370-4fea-9d1c-d8be066389c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_raster(fn, bbox=None):\n",
    "    rxr_obj = rxr.open_rasterio(fn, masked=True).squeeze()\n",
    "    if bbox:\n",
    "        minx,miny,maxx,maxy = bbox\n",
    "        # Sometimes have min & max ordering wrong when copying & pasting\n",
    "        minx,miny,maxx,maxy = min(minx,maxx),min(miny,maxy),max(minx,maxx),max(miny,maxy)\n",
    "        return rxr_obj.rio.clip_box(minx,miny,maxx,maxy)\n",
    "    else:\n",
    "        return rxr_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db4338c-a32b-400c-8613-565cc6ca1f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stretch_image(img):\n",
    "    # https://stackoverflow.com/questions/60449340/contrast-enhancement-using-a-percentage-cumulative-count-in-matplolib\n",
    "    min_percent = 2   # Low percentile\n",
    "    max_percent = 98  # High percentile\n",
    "    lo, hi = np.percentile(img, (min_percent, max_percent))\n",
    "\n",
    "    # Apply linear \"stretch\" - lo goes to 0, and hi goes to 1\n",
    "    res_img = (img.astype(float) - lo) / (hi-lo)\n",
    "\n",
    "    #Multiply by 255, clamp range to [0, 255] and convert to uint8\n",
    "    res_img = np.maximum(np.minimum(res_img*255, 255), 0).astype(np.uint8)\n",
    "    return res_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307a0f67-5c0e-43be-83e5-9b2bdeb7f9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_shaded_relief(ax, dem_fn, bbox, title):\n",
    "    hs_fn = \"tmphillshade.tif\"\n",
    "    ds = gdal.Open(dem_fn)\n",
    "    # Creates a new file in this directory, could delete or retain if desired\n",
    "    gdal.DEMProcessing(hs_fn, ds, \"hillshade\", computeEdges=True)\n",
    "    ds = None\n",
    "    dem = open_raster(dem_fn, bbox=bbox)\n",
    "    hs = open_raster(hs_fn, bbox=bbox)\n",
    "    # dem = dem.squeeze()\n",
    "    # hs = hillshade(dem)\n",
    "    ax.imshow(hs, cmap=\"gray\", rasterized=True)\n",
    "    im = ax.imshow(dem, cmap=\"viridis\", alpha=0.5, rasterized=True)\n",
    "    plt.colorbar(im, ax=ax, fraction=0.04)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_aspect(1)\n",
    "    ax.set_title(title)\n",
    "\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b4671b-40f7-4967-95c0-9ea3f476c9d3",
   "metadata": {},
   "source": [
    "## Commands to run training & inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e515222-b61f-4df4-8913-449802f7af83",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980d29ae-2227-465a-af0d-ec425b13d140",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd $script_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9522c1e-9b3a-45e7-9a2e-c1001d5f2ea3",
   "metadata": {},
   "source": [
    "### Training with LightningCLI and a configuration file\n",
    "* (encourage switch to use of the LightningCLI approach of `train_cli.py` instead of `train.py` which was used for most previous experiments and has all implemented features, but was limiting due to its mix of configuration and code)\n",
    "* To train with a different dataset, modify the configuration file by providing lists of training & validation directories appropriately.\n",
    "* To load a model from a checkpoint, define this in the YAML. Example:\n",
    "    * `max_epochs: 1234567890`\n",
    "    * `ckpt_path: \"/path/to/epoch=12366-step=3091750.ckpt\"`\n",
    "    * Make sure normalization choice (i.e. `meanstd`) & list of input layers match what was used to train the model!\n",
    "* When training monitor the losses and evaluate output carefully, find the high-loss examples (e.g. deep forest had offsets orders of magnitude larger than non-forested areas, and were inhibiting progress with 2022 experiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c563a0-a79c-4901-b8aa-bed824bd0a66",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!python train_cli.py fit -c $repo_dir/configs/example_config.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3eea0d9-7f79-42cd-b7c6-42e060e9af2d",
   "metadata": {},
   "source": [
    "### Run inference\n",
    "* The inference script could also be replaced by LightningCLI if there is a way to sample the entire dataset and stitch outputs into a raster. This would avoid issues with implementing a separate CLI and redundant/brittle code dealing with normalization of layers, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0dea66b-c5a1-4444-aca5-d6f2d651a374",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_output_fn = \"inference_tg041_1024x1024.tif\"\n",
    "!python inference.py $main_dir/epoch=12366-step=3091750.ckpt \\\n",
    "    meanstd  \\\n",
    "    $inference_output_fn \\\n",
    "    stucker_unet \\\n",
    "    cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16984b1f-5ed5-479a-a6e1-9a8bc0bb8a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reuse Baker CSM stack filenames from torchgeo_dataset.py\n",
    "\n",
    "# initial_dem_unfilled_root = \"try_pc_align_to_lidar_15m_maxdisp_rotationallowed-1.0m-DEM.tif\"\n",
    "baker_stack_dir = f\"{main_dir}/baker_csm_stack_small\"\n",
    "\n",
    "# Bring in the inference result\n",
    "inference_output_path = os.path.join(baker_stack_dir, os.path.basename(inference_output_fn))\n",
    "!cp $inference_output_fn $inference_output_path\n",
    "\n",
    "initial_dem_root = os.path.join(baker_stack_dir, \"try_pc_align_to_lidar_15m_maxdisp_rotationallowed-1.0m-DEM_holes_filled.tif\")\n",
    "ortho_left_root = os.path.join(baker_stack_dir, \"final_ortho_left_1.0m.tif\")\n",
    "ortho_right_root = os.path.join(baker_stack_dir, \"final_ortho_right_1.0m.tif\")\n",
    "triangulation_error_root = os.path.join(baker_stack_dir, \"try_pc_align_to_lidar_15m_maxdisp_rotationallowed-1.0m-IntersectionErr.tif\")#_holes_filled.tif\")\n",
    "target_root = os.path.join(baker_stack_dir, \"mosaic_full128_USGS_LPC_WA_MtBaker_2015___LAS_2017_32610_first_filt_v1.3_1.0m-DEM_holes_filled.tif\")\n",
    "# Note: target_root had a `_*_` in it before, filename changed at some point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8188e1fb-a841-4aff-b1f8-fa675cb7c0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c189b6-ebea-43d3-a9e8-f9ff01c68cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd $main_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff95999-b8fa-4c16-9de6-aafa87db4b40",
   "metadata": {},
   "source": [
    "## Plot output vs input datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5dcaa6-4baa-43ab-8495-f24afc731e9a",
   "metadata": {},
   "source": [
    "**It is also a good idea to use hillshades and difference maps to compare the refined DEM to input and target DEMs, with evaluation scripts, interactive notebooks, and/or QGIS.**\n",
    "More plotting code can be found within the notebook directory or the `eval.py` script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b492c39c-fde4-45d8-b268-6e6d840ddac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_channel_and_tree_spot = (585825,5398225, 586900,5397475)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bed550f-4969-4666-b744-a0dbee98a2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dpi = 500\n",
    "output_choice = inference_output_path\n",
    "\n",
    "output_choice = output_v129_11758 # output_v140_11632#\n",
    "run_name = os.path.splitext(os.path.basename(output_choice))[0]\n",
    "plot_title = f\"Plot Baker training area {train_channel_and_tree_spot}\\n{run_name}\"\n",
    "nrows=2\n",
    "ncols=2\n",
    "fig, axes = plt.subplots(ncols=ncols, nrows=nrows, dpi=dpi,figsize=(10,7.5))# figsize=(ncols * 4, nrows * 4 + 1), )\n",
    "axes = axes.reshape(-1)\n",
    "\n",
    "fig.suptitle(plot_title)\n",
    "\n",
    "    \n",
    "plot_ortho(axes[0], open_raster(ortho_left_root, bbox=train_channel_and_tree_spot), \"Orthoimage (stretched)\")\n",
    "plot_shaded_relief(axes[1], initial_dem_root, train_channel_and_tree_spot, \"Initial DEM (meters)\")\n",
    "plot_shaded_relief(axes[2], output_choice, train_channel_and_tree_spot, \"Refined DEM (meters)\")\n",
    "plot_shaded_relief(axes[3], target_root, train_channel_and_tree_spot, \"Lidar DEM (meters)\")\n",
    "\n",
    "\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
